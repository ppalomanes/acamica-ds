{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13130</th>\n",
       "      <td>0</td>\n",
       "      <td>#food#my#love ð¤ð¤ðð @ dongguan, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>0</td>\n",
       "      <td>you are... brave you are bold  you are beautif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>0</td>\n",
       "      <td>#mountains   rooster simulation: i want to cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>0</td>\n",
       "      <td>@user got my bayolea shave soap order on its w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>0</td>\n",
       "      <td>happy with my new clothes ðððâ¤ð ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "id                                                             \n",
       "13130      0   #food#my#love ð¤ð¤ðð @ dongguan, ch...\n",
       "1767       0  you are... brave you are bold  you are beautif...\n",
       "9310       0  #mountains   rooster simulation: i want to cli...\n",
       "10958      0  @user got my bayolea shave soap order on its w...\n",
       "13497      0  happy with my new clothes ðððâ¤ð ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29530"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦                                                    319\n",
       "i finally found a way how to delete old tweets! you might find it useful as well:    #deletetweets                                       82\n",
       "aww yeah it's all good bing bong bing bong                                                                                               75\n",
       "i'm so   and #grateful now that - #affirmations                                                                                          56\n",
       "@user you might be a libtard if... #libtard  #sjw #liberal #politics                                                                     40\n",
       "you might be a libtard if... #libtard  #sjw #liberal #politics                                                                           32\n",
       "ð #love #instagood #photooftheday top.tags #tbt #cute #me #beautiful #followme   #followâ¦                                           29\n",
       "have my lover stop being angry at me visit us..&gt;&gt;&gt;  #lover   #friend #astrologer #love                                          26\n",
       "#flagday2016   #flag #day #2016 #(30 #photos) buy things about \"flag day 2016\": â¦                                                      22\n",
       "get #up get   get  #enjoy #music #today #free #apps #free #music                                                                         21\n",
       "@user #feminismiscancer #feminismisterrorism #feminismmuktbharat why  #malevote is ignored  @user                                        20\n",
       "#sikh #temple vandalised in in #calgary, #wso condemns  act                                                                              20\n",
       "save $$ no logins x brokers   #me #change #memes #love   #education #university                                                          17\n",
       "can #lighttherapy help with   or #depression?    #altwaystoheal  #healthy is #happy !!                                                   16\n",
       "can #lighttherapy help with   or #depression?   #altwaystoheal #healthy is #happy !!                                                     14\n",
       "#music as #therapy as a tool for #healing!   #altwaystoheal #healthy is  !!                                                              14\n",
       "what is a #detoxdiet?  #altwaystoheal! #healthy  !                                                                                       14\n",
       "does #magnettherapy really work?   #altwaystoheal #healing #healthy   !!                                                                 14\n",
       "best #essentialoils for #anxiety !!     #healthy   #peace !!  #altwaystoheal !!                                                          14\n",
       "safe ways to heal your #acne!!    #altwaystoheal #healthy   #healing!!                                                                   14\n",
       "best essential oils for #healing!!    #altwaystoheal #healthy  !!                                                                        14\n",
       "herbal sleep remedies that work!!  #altwaystoheal #healthy #healing   !!                                                                 13\n",
       "looking to feel more #joy? join me and 20 speakers on the free summit #unleashyourjoy                                                    13\n",
       "best #lawofattraction #resources for #healing!    #altwaystoheal #healthy is  ! #idwp !                                                  13\n",
       "#raw food diet benefits! -    #altwaystoheal #healthy   #healing #peace #joy #love !!                                                    12\n",
       "can #lighttherapy help with #sad or #depression?    #altwaystoheal  #healthy is   !!                                                     12\n",
       "#lawofattraction for #healing!!    #altwaystoheal #healthy is  !!                                                                        12\n",
       "best #essentialoils for #anxiety !!     #healthy   #peace !! #altwaystoheal !!                                                           11\n",
       "can #atherapy and #musictherapy heal your life?   #altwaystoheal #healthy   #healing!                                                    11\n",
       "  happy day!  #altwaystoheal  #healthy                                                                                                   11\n",
       "                                                                                                                                       ... \n",
       "life is meaningless you have to find a purpose. #not   #just #fax                                                                         1\n",
       "@user fuming! reserved some shoes at your stratford branch, went all the way there and staff have sold them anyways!                      1\n",
       "@user @user you can't hate radical islamic terrorists now? america in 2016.  .                                                            1\n",
       " @user @user #momsterlink all linked up  &amp;  #firsttime #very                                                                          1\n",
       "wait lets do it this way someone has some suggestions that need to be in my playlist for my next streams                                  1\n",
       "#achievementunlocked monday check! passed the 5 days! did it all right! #success i am a #fighter #brandnew   #fitness #workout            1\n",
       " @user punching things&gt;&gt;  ð¡ #ihateschool                                                                                         1\n",
       "angry birds meets red nurse game for kids  birds #rednurse #pig  #game                                                                    1\n",
       "@user i'm surprised they didn't have a gun, they usually carry guns every where else,     man                                             1\n",
       "it's true... Ãverything in life &amp; love changes when you got little elfs hoppin' around. especially mÃ©   #love                       1\n",
       "another   #customer!  snow day has a new home ! #pencila #lovinglife #proudmoment #yycâ¦                                                 1\n",
       " @user i have no idea why i love him so much. it's so weird but @user really is my favorite person ever                                   1\n",
       "ð­sad asfk and idk y                                                                                                                    1\n",
       "#fashion it is a true   #fact                                                                                                             1\n",
       "our heas, thoughts, prayers go out to the more than 50 people who were murdered @ a gay nightclub in #florida                             1\n",
       " @user ðð fave ðð                                                                                                             1\n",
       "when you get your favourite cousin turn up for a cheeky drink   #emotional ð                                                           1\n",
       "[1465521171.6] update @  #social #analytics #geek #v8supercars   #followme #value                                                         1\n",
       "  champions trophy: coach roelant oltmans happy with india's next-gen hockey players: london: india's ho...                               1\n",
       " @user #gold ! very special nr13 qualified for #ech2016 #amsterdam2016   #adidasrunningâ¦                                                1\n",
       " scoopwhoopnews: 80-yr-old hindu man #gokaldas beaten up by cop in #pakistan for eating during roza hrs!   â¦                            1\n",
       "#mtv went #fullretard on  video #nzpol #auspol #merkel #retard for #hispters #mansplaining #svpol #theview                                1\n",
       "  #caturday today #ripchristina #saturday #rip                                                                                            1\n",
       "anderson cooper fought back tears as he shared a poignant seven-minute tribute to the ...    #lostlovedones                               1\n",
       "ð   india and singapore sign key agreement to boost maritime                                                                           1\n",
       "@user happy 1st anniversary hina di ððâ£ðâ¤ðððon twitter blessed day fr all hinaholicsð¤  usð#lovelovelove       1\n",
       "fuck donald trump! he will never be my president! #opkkk #optrump  #illegitimate #oligarch #plutocrat  #shill                             1\n",
       "@user you're so close to 11 million subs! squeeee!!!!!!!   #11millionsubs                                                                 1\n",
       "felt so sad for @user  last night! #hug   #freshsta                                                                                       1\n",
       "  45th #bihday hardrockcafelondon  thanks for the fantastic food and staff ~ @user                                                        1\n",
       "Name: tweet, Length: 29530, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/rcrespillo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_lemm(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(tweet)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x : tweets_lemm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"tweet\"]\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                             tokenizer=nltk.word_tokenize, \n",
    "                             stop_words=stops, \n",
    "                             ngram_range=(1,3))\n",
    "\n",
    "X_train_v = vectorizer.fit_transform(X_train)\n",
    "X_test_v = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'hidden_layer_sizes': [(10,),(5,5), (2,2)]}\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.fit(X_train_v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_clf.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"roc_auc score: {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = vectorizer.transform(X)\n",
    "y_all = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = vectorizer.transform(df_test['tweet'])\n",
    "test_pred = mlp_clf.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test[['id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sub_rodixxi_mlpc_lemmatizer_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
