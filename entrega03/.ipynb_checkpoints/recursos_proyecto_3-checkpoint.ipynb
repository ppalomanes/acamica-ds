{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 3: Predicción de precios de propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Bienvenidos al tercer proyecto de la carrera de Data Science de Acamica! \n",
    "\n",
    "En este proyecto vamos a seguir trabajando con el dataset de propiedades en venta publicadas en el portal [Properati](www.properati.com.ar). El objetivo en este caso armar nuestros primeros modelos para predecir el precio de las propiedades en dólares.\n",
    "\n",
    "Las columnas que se agregan son:\n",
    "\n",
    "* `barrios_match`: si coincide el barrio publicado con el geográfico vale 1, si no 0.\n",
    "\n",
    "* `PH`, `apartment`, `house`: variables binarias que indican el tipo de propiedad.\n",
    "\n",
    "* dummies de barrios: variables binarias con 1 o 0 según el barrio.\n",
    "\n",
    "La métrica que vamos a usar para medir es RMSE (raíz del error cuadrático medio), cuya fórmula es:\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{\\sum_{t=1}^n (\\hat y_t - y_t)^2}{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "path_dataset = 'dataset/datos_properati_limpios_model.csv'\n",
    "df = pd.read_csv(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset que vamos a trabajar aquí tiene 6376 observaciones\n"
     ]
    }
   ],
   "source": [
    "print(\"El dataset que vamos a trabajar aquí tiene {} observaciones\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este proyecto es poder trabajar en el ajuste de modelos y su posterior evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar vamos a separar el `dataset` en un conjunto de entrenamiento (80%) y un conjunto de test (20%). \n",
    "\n",
    "**Separá el dataset** en `X_train`, `X_test`, `y_train` e `y_test` con el tamaño correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price_aprox_usd'], axis=1)\n",
    "y = df['price_aprox_usd']\n",
    "\n",
    "# Realizá la separación a continuación en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de decisión\n",
    "\n",
    "Lo primero que vamos a hacer es entrena un árbol de decisión y usar de métrica `RMSE`. \n",
    "\n",
    "Para poder obtener el RMSE vamos a medir usando `neg_mean_squared_error` . Para obtenerlo, tenemos que cambiar los signos y tomar raiz en cada caso.\n",
    "\n",
    "**Importá** `DecisionTreeRegressor` desde `sklearn.tree`.  \n",
    "\n",
    "A continuación **entrená** el regresor con los conjuntos de training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda cargá el regresor y realizá el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo entrenado **realizá la predicción** sobre el conjunto de test `X_test` y guardá el resultado en una variable `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá realizá la predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculá el rmse** sacando la raíz cuadrada de `mean_squared_error` entre `y_test` e `y_pred` y **mostrá** el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda calculá el rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analizar el cambio en el RMSE a medida que es más profundo el árbol de decisión, tanto en training como en testing.__\n",
    "\n",
    "Para esto, **iterá** de 5 en 5 en el parámetro `max_depth` y **observá** como impacta en el RMSE. \n",
    "\n",
    "**Creá** dos arreglos `rmses_train` y `rmses_test` para ir guardando los **rmse** de cada profundidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora graficamos los valores que guardamos en los arreglos `rmses_train` y `rmses_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.plot(range(1,30, 5), rmses_train, label='RMSE Training')\n",
    "plt.plot(range(1,30, 5), rmses_test, label='RMSE Testing')\n",
    "plt.ylim((0, 30000))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"RMSE Training vs RMSE Testing para árboles de decisión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver aquí como el modelo presenta sobreajuste dado que a mayor complejidad (en este caso, mayor profundidad del árbol) más diferencia entre los resultados de training y testing. También observamos como la curva de testing decrece y luego vuelvo a crecer. El punto donde se minimiza está relacionado con el tradeoff entre sesgo y varianza que vamos a ver en la próxima unidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrená un knn** y nuevamente medir el **rmse** en el conjunto de testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizá el entrenamiento y el cálculo de rmse en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analizar el cambio en el RMSE a medida que consideramos más vecinos para KNN, tanto en training como en testing.__\n",
    "\n",
    "Para esto, **iterá** incrementando de a uno el parámetro `n_neighbors` y **observá** como impacta en el RMSE. \n",
    "\n",
    "**Creá** dos arreglos `rmses_train` y `rmses_test` para ir guardando los **rmse** de cada profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculá los cambio en el rmse en esta celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,30, 1), rmses_train, label='RMSE Training')\n",
    "plt.plot(range(1,30, 1), rmses_test, label='RMSE Testing')\n",
    "plt.ylim((0, 30000))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"RMSE Training vs RMSE Testing para KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calcular el RMSE promedio de cross validation (10 folds) para un árbol de decisión de máxima profundidad 5.__\n",
    "\n",
    "Dado que la implementación de scikit-learn usá el `neg_mean_squared_error` para calcular en cross validation, definamos el método nmsq2rmse para pasar de esa métrica al RMSE que venimos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmsq2rmse(score):\n",
    "    return np.sqrt(-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos cross validation para analizar el resultado de estos parámetros para árboles de decisión. Recordemos que el resultado de cross validation es la performance en testing para cada partición. Una vez evaluado esto, podemos comparar entre modelos y cuando hayamos elegido el favorito, procedemos a ajustar y predecir.\n",
    "\n",
    "**Calculá** los `neg_scores` utilizando `cross_val_score`(tendras que importarlo) utilizando 10-fold cv. El parametro de `scoring` será `neg_mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculá en esta celda los cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el resultado final, reentrenamos al regresor y mostramos en un dataframe la comparación entre los valores reales, los predichos y su diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "val_real = pd.Series(y_test.values)\n",
    "val_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = pd.concat([val_real.rename('Valor real'),val_pred.rename('Valor Pred') ,abs(val_real-val_pred).rename('Dif(+/-)')] ,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
