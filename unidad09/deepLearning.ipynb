{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(twenty_train.data)\n",
    "X_test = tf_idf.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141145139813582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,), random_state=42)\n",
    "mlp_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300932090545939"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                572624    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 572,964\n",
      "Trainable params: 572,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(max_features,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1805 samples, validate on 452 samples\n",
      "Epoch 1/50\n",
      "1805/1805 [==============================] - 1s 679us/step - loss: 1.3765 - acc: 0.3873 - val_loss: 1.3525 - val_acc: 0.5619\n",
      "Epoch 2/50\n",
      "1805/1805 [==============================] - 1s 505us/step - loss: 1.3312 - acc: 0.6183 - val_loss: 1.3188 - val_acc: 0.6327\n",
      "Epoch 3/50\n",
      "1805/1805 [==============================] - 1s 465us/step - loss: 1.2881 - acc: 0.7069 - val_loss: 1.2877 - val_acc: 0.6681\n",
      "Epoch 4/50\n",
      "1805/1805 [==============================] - 1s 461us/step - loss: 1.2476 - acc: 0.7507 - val_loss: 1.2584 - val_acc: 0.7035\n",
      "Epoch 5/50\n",
      "1805/1805 [==============================] - 1s 495us/step - loss: 1.2087 - acc: 0.8083 - val_loss: 1.2292 - val_acc: 0.7367\n",
      "Epoch 6/50\n",
      "1805/1805 [==============================] - 1s 456us/step - loss: 1.1695 - acc: 0.8737 - val_loss: 1.2015 - val_acc: 0.7345\n",
      "Epoch 7/50\n",
      "1805/1805 [==============================] - 1s 482us/step - loss: 1.1308 - acc: 0.9042 - val_loss: 1.1710 - val_acc: 0.7832\n",
      "Epoch 8/50\n",
      "1805/1805 [==============================] - 1s 485us/step - loss: 1.0922 - acc: 0.9407 - val_loss: 1.1427 - val_acc: 0.7942\n",
      "Epoch 9/50\n",
      "1805/1805 [==============================] - 1s 516us/step - loss: 1.0529 - acc: 0.9634 - val_loss: 1.1118 - val_acc: 0.8119\n",
      "Epoch 10/50\n",
      "1805/1805 [==============================] - 1s 552us/step - loss: 1.0132 - acc: 0.9729 - val_loss: 1.0807 - val_acc: 0.8296\n",
      "Epoch 11/50\n",
      "1805/1805 [==============================] - 1s 525us/step - loss: 0.9733 - acc: 0.9773 - val_loss: 1.0484 - val_acc: 0.8606\n",
      "Epoch 12/50\n",
      "1805/1805 [==============================] - 1s 597us/step - loss: 0.9329 - acc: 0.9834 - val_loss: 1.0183 - val_acc: 0.8540\n",
      "Epoch 13/50\n",
      "1805/1805 [==============================] - 1s 607us/step - loss: 0.8920 - acc: 0.9867 - val_loss: 0.9843 - val_acc: 0.8850\n",
      "Epoch 14/50\n",
      "1805/1805 [==============================] - 1s 632us/step - loss: 0.8516 - acc: 0.9900 - val_loss: 0.9515 - val_acc: 0.8938\n",
      "Epoch 15/50\n",
      "1805/1805 [==============================] - 1s 598us/step - loss: 0.8115 - acc: 0.9911 - val_loss: 0.9191 - val_acc: 0.9004\n",
      "Epoch 16/50\n",
      "1805/1805 [==============================] - 1s 726us/step - loss: 0.7708 - acc: 0.9928 - val_loss: 0.8877 - val_acc: 0.8960\n",
      "Epoch 17/50\n",
      "1805/1805 [==============================] - 1s 803us/step - loss: 0.7301 - acc: 0.9950 - val_loss: 0.8562 - val_acc: 0.8938\n",
      "Epoch 18/50\n",
      "1805/1805 [==============================] - 1s 744us/step - loss: 0.6906 - acc: 0.9950 - val_loss: 0.8213 - val_acc: 0.9027\n",
      "Epoch 19/50\n",
      "1805/1805 [==============================] - 1s 611us/step - loss: 0.6514 - acc: 0.9967 - val_loss: 0.7878 - val_acc: 0.9071\n",
      "Epoch 20/50\n",
      "1805/1805 [==============================] - 1s 614us/step - loss: 0.6128 - acc: 0.9972 - val_loss: 0.7562 - val_acc: 0.9093\n",
      "Epoch 21/50\n",
      "1805/1805 [==============================] - 2s 971us/step - loss: 0.5749 - acc: 0.9978 - val_loss: 0.7244 - val_acc: 0.9115\n",
      "Epoch 22/50\n",
      "1805/1805 [==============================] - 1s 828us/step - loss: 0.5381 - acc: 0.9983 - val_loss: 0.6911 - val_acc: 0.9137\n",
      "Epoch 23/50\n",
      "1805/1805 [==============================] - 1s 815us/step - loss: 0.5024 - acc: 0.9989 - val_loss: 0.6627 - val_acc: 0.9159\n",
      "Epoch 24/50\n",
      "1805/1805 [==============================] - 2s 884us/step - loss: 0.4676 - acc: 0.9994 - val_loss: 0.6330 - val_acc: 0.9204\n",
      "Epoch 25/50\n",
      "1805/1805 [==============================] - 1s 780us/step - loss: 0.4340 - acc: 0.9994 - val_loss: 0.6013 - val_acc: 0.9248\n",
      "Epoch 26/50\n",
      "1805/1805 [==============================] - 1s 648us/step - loss: 0.4017 - acc: 0.9994 - val_loss: 0.5727 - val_acc: 0.9248\n",
      "Epoch 27/50\n",
      "1805/1805 [==============================] - 1s 637us/step - loss: 0.3709 - acc: 0.9994 - val_loss: 0.5450 - val_acc: 0.9292\n",
      "Epoch 28/50\n",
      "1805/1805 [==============================] - 1s 495us/step - loss: 0.3415 - acc: 0.9994 - val_loss: 0.5150 - val_acc: 0.9336\n",
      "Epoch 29/50\n",
      "1805/1805 [==============================] - 1s 465us/step - loss: 0.3136 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.9336\n",
      "Epoch 30/50\n",
      "1805/1805 [==============================] - 1s 535us/step - loss: 0.2873 - acc: 1.0000 - val_loss: 0.4651 - val_acc: 0.9381\n",
      "Epoch 31/50\n",
      "1805/1805 [==============================] - 1s 580us/step - loss: 0.2624 - acc: 1.0000 - val_loss: 0.4411 - val_acc: 0.9358\n",
      "Epoch 32/50\n",
      "1805/1805 [==============================] - 1s 581us/step - loss: 0.2391 - acc: 1.0000 - val_loss: 0.4191 - val_acc: 0.9358\n",
      "Epoch 33/50\n",
      "1805/1805 [==============================] - 2s 842us/step - loss: 0.2172 - acc: 1.0000 - val_loss: 0.3949 - val_acc: 0.9403\n",
      "Epoch 34/50\n",
      "1805/1805 [==============================] - 1s 785us/step - loss: 0.1969 - acc: 1.0000 - val_loss: 0.3764 - val_acc: 0.9447\n",
      "Epoch 35/50\n",
      "1805/1805 [==============================] - 1s 594us/step - loss: 0.1780 - acc: 0.9994 - val_loss: 0.3579 - val_acc: 0.9491\n",
      "Epoch 36/50\n",
      "1805/1805 [==============================] - 1s 614us/step - loss: 0.1606 - acc: 1.0000 - val_loss: 0.3371 - val_acc: 0.9491\n",
      "Epoch 37/50\n",
      "1805/1805 [==============================] - 1s 572us/step - loss: 0.1445 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.9602\n",
      "Epoch 38/50\n",
      "1805/1805 [==============================] - 2s 935us/step - loss: 0.1299 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.9602\n",
      "Epoch 39/50\n",
      "1805/1805 [==============================] - 2s 903us/step - loss: 0.1163 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 0.9624\n",
      "Epoch 40/50\n",
      "1805/1805 [==============================] - 1s 781us/step - loss: 0.1043 - acc: 1.0000 - val_loss: 0.2708 - val_acc: 0.9624\n",
      "Epoch 41/50\n",
      "1805/1805 [==============================] - 2s 937us/step - loss: 0.0932 - acc: 1.0000 - val_loss: 0.2573 - val_acc: 0.9624\n",
      "Epoch 42/50\n",
      "1805/1805 [==============================] - 1s 752us/step - loss: 0.0831 - acc: 1.0000 - val_loss: 0.2442 - val_acc: 0.9646\n",
      "Epoch 43/50\n",
      "1805/1805 [==============================] - 1s 620us/step - loss: 0.0740 - acc: 1.0000 - val_loss: 0.2345 - val_acc: 0.9624\n",
      "Epoch 44/50\n",
      "1805/1805 [==============================] - 1s 622us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9646\n",
      "Epoch 45/50\n",
      "1805/1805 [==============================] - 1s 783us/step - loss: 0.0586 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.9646\n",
      "Epoch 46/50\n",
      "1805/1805 [==============================] - 2s 919us/step - loss: 0.0521 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 0.9668\n",
      "Epoch 47/50\n",
      "1805/1805 [==============================] - 1s 771us/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9668\n",
      "Epoch 48/50\n",
      "1805/1805 [==============================] - 2s 898us/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9668\n",
      "Epoch 49/50\n",
      "1805/1805 [==============================] - 1s 783us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9668\n",
      "Epoch 50/50\n",
      "1805/1805 [==============================] - 1s 657us/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5e512dc9e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,dummy_y,batch_size=512,epochs=50,verbose=1,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194407456724367\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
